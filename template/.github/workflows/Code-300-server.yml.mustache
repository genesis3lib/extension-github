name: Code-300-Server
on:
  push:
  workflow_dispatch:

permissions:
  contents: read
  checks: write
  id-token: write

env:
  TF_VERSION: "1.12.2"
  AWS_REGION: {{region}}

jobs:
  server-operations:
    runs-on: ubuntu-latest
    steps:
      - name: Version of AWS CLI
        run: |
          echo "AWS CLI version:"
          which aws
          aws --version

      - name: Checkout code
        uses: actions/checkout@v4

      - name: Env setup
        run: |
          
          # Set environment variables
          echo "BRANCH={{{githubVarsOpen}}} github.ref_name  {{{githubVarsClose}}}" >> $GITHUB_ENV
          if [[ "{{{githubVarsOpen}}} github.ref_name  {{{githubVarsClose}}}" = "main" || "{{{githubVarsOpen}}} github.ref_name  {{{githubVarsClose}}}" = "production" ]]; then
            echo "ENVIRONMENT=production" >> $GITHUB_ENV
          else
            BRANCH_ENV=$(echo "{{{githubVarsOpen}}} github.ref_name  {{{githubVarsClose}}}" | sed "s///-/g")
            echo "ENVIRONMENT=$BRANCH_ENV" >> $GITHUB_ENV
          fi
          
          echo "‚úÖ Environment setup completed: {{{githubVarsOpen}}} github.ref_name  {{{githubVarsClose}}}"

      - name: Credential for AWS
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: arn:aws:iam::{{{githubVarsOpen}}} vars.AWS_ACCOUNT_ID {{{githubVarsClose}}}:role/{{projectName}}-{{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}-ops-deploy-ec2-role
          aws-region: {{{githubVarsOpen}}} env.AWS_REGION  {{{githubVarsClose}}}

      - name: Setup Environment
        run: |
          echo "Event name: {{{githubVarsOpen}}} github.event_name  {{{githubVarsClose}}}"
          echo "Branch: {{{githubVarsOpen}}} env.BRANCH  {{{githubVarsClose}}}"
          echo "Environment: {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}"

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v3
        with:
          terraform_version: {{{githubVarsOpen}}} env.TF_VERSION  {{{githubVarsClose}}}
          terraform_wrapper: false

      - name: Get Terraform Outputs
        run: |
          cd {{id}}/terraform
          echo "üîç Getting Terraform outputs for {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}} environment..."
          
          # Initialize Terraform to access state
          terraform init -backend-config=backend-${ENVIRONMENT}.hcl -input=false
          
          # Get the ops bucket name from Terraform outputs
          OPS_BUCKET=$(terraform output -raw ops_bucket_name 2>/dev/null || echo "")
          
          if [ -z "$OPS_BUCKET" ]; then
            echo "‚ùå Could not get ops bucket from Terraform outputs"
            echo "üîç Available Terraform outputs:"
            terraform output
            echo "‚ö†Ô∏è Infrastructure may not be deployed yet - run deploy_apply first"
            exit 1
          fi
          
          echo "‚úÖ Found ops bucket: $OPS_BUCKET"
          echo "OPS_BUCKET=$OPS_BUCKET" >> $GITHUB_ENV
        env:
          AWS_DEFAULT_REGION: {{{githubVarsOpen}}} env.AWS_REGION  {{{githubVarsClose}}}

      - name: Set Deployment Environment Variables  
        run: |
          echo "üîß Setting up deployment environment variables..."
          
          # Set SPRING_PROFILE based on ENVIRONMENT
          echo "SPRING_PROFILE={{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}" >> $GITHUB_ENV
          echo "‚úÖ SPRING_PROFILE set to: {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}"
          
          echo "üìã Environment Variables Set:"
          echo "  SPRING_PROFILE: {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}"
          echo "  OPS_BUCKET: ${OPS_BUCKET}"

      - name: Get EC2 Instances by Tags
        run: |
          echo "üîç Finding EC2 instances by tags..."
          echo "Looking for instances with Project={{projectName}} and Environment={{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}"
          
          # Query EC2 instances by tags
          EC2_INSTANCES=$(aws ec2 describe-instances \
            --filters \
              "Name=tag:Project,Values={{projectName}}" \
              "Name=tag:Environment,Values={{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}" \
              "Name=instance-state-name,Values=running" \
            --query 'Reservations[*].Instances[*].InstanceId' \
            --output text | tr '\n\t ' ',' | sed 's/,,*/,/g' | sed 's/^,//g' | sed 's/,$//g')
          
          if [ -n "${EC2_INSTANCES}" ] && [ "${EC2_INSTANCES}" != "" ]; then
            echo "EC2_INSTANCES=${EC2_INSTANCES}" >> $GITHUB_ENV
            echo "‚úÖ Found running instances: ${EC2_INSTANCES}"
          else
            echo "‚ùå No running instances found with tags Project={{projectName}} and Environment={{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}"
            echo "This could indicate:"
            echo "  1. Instances are still launching"
            echo "  2. Instances failed to start properly" 
            echo "  3. Infrastructure deployment is incomplete"
            echo ""
            echo "All instances in environment:"
            aws ec2 describe-instances \
              --filters \
                "Name=tag:Project,Values={{projectName}}" \
                "Name=tag:Environment,Values={{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}" \
              --query 'Reservations[*].Instances[*].{InstanceId:InstanceId,State:State.Name,Name:Tags[?Key==`Name`].Value|[0]}' \
              --output table
            exit 1
          fi

      - name: Deploy - Add build info
        run: |
          mkdir -p {{backendModule.id}}/src/main/resources
          echo -e "gh.build={{{githubVarsOpen}}} github.run_number  {{{githubVarsClose}}}\\ngh.attempt={{{githubVarsOpen}}} github.run_attempt  {{{githubVarsClose}}}\\ngh.action={{{githubVarsOpen}}} github.action  {{{githubVarsClose}}}\\ngh.modifiedDate={{{githubVarsOpen}}} github.event.repository.updated_at  {{{githubVarsClose}}}\\ngh.sha=$( git rev-parse --short HEAD )" > {{backendModule.id}}/src/main/resources/version.properties

      - name: Deploy - Set up JDK 21
        uses: actions/setup-java@v4
        with:
          distribution: 'adopt'
          java-version: '21'

      - name: Deploy - Setup Gradle
        uses: gradle/gradle-build-action@v2
        with:
          gradle-version: current
    
      - name: Deploy - Build Application (with tests)
        run: |
          cd {{backendModule.id}}
          gradle -PversionArg=1.0.{{{githubVarsOpen}}} github.run_number  {{{githubVarsClose}}}.{{{githubVarsOpen}}} github.run_attempt  {{{githubVarsClose}}} bootJar -x test

      - name: Deploy - Sync JAR to S3
        run: |
          JAR_NAME="{{backendModule.name}}-api-1.0.{{{githubVarsOpen}}} github.run_number  {{{githubVarsClose}}}.{{{githubVarsOpen}}} github.run_attempt  {{{githubVarsClose}}}.jar"
          echo "üì¶ Syncing JAR to S3 ops bucket: ${OPS_BUCKET}/jars/"
          echo "JAR: ${JAR_NAME}"
          
          # Verify JAR file exists
          if [ ! -f "{{backendModule.id}}/build/libs/${JAR_NAME}" ]; then
            echo "‚ùå JAR file not found: {{backendModule.id}}/build/libs/${JAR_NAME}"
            echo "üìÅ Available files in {{backendModule.id}}/build/libs/:"
            ls -la {{backendModule.id}}/build/libs/ || echo "Directory not found"
            exit 1
          fi
          
          # Show JAR file info
          echo "üìã JAR file details:"
          ls -lh "{{backendModule.id}}/build/libs/${JAR_NAME}"
          
          # Create a staging directory for sync
          mkdir -p ./staging/jars
          cp {{backendModule.id}}/build/libs/${JAR_NAME} "./staging/jars/"
          
          # Sync the staging/jars directory to S3
          echo "üöÄ Syncing JAR to S3..."
          if aws s3 sync ./staging/jars/ "s3://${OPS_BUCKET}/jars/" --region {{{githubVarsOpen}}} env.AWS_REGION  {{{githubVarsClose}}}; then
            echo "‚úÖ Successfully synced JAR to S3 ops bucket"
            echo "JAR_NAME=${JAR_NAME}" >> $GITHUB_ENV
            
            # Verify what was uploaded
            echo "üîç Verifying uploaded JAR:"
            aws s3 ls "s3://${OPS_BUCKET}/jars/${JAR_NAME}" --region {{{githubVarsOpen}}} env.AWS_REGION  {{{githubVarsClose}}}
            
            # Clean up staging directory
            rm -rf ./staging
          else
            echo "‚ùå Failed to sync JAR to S3 ops bucket: ${OPS_BUCKET}"
            rm -rf ./staging
            exit 1
          fi

      - name: Deploy - Sync EC2 Setup Scripts to S3
        run: |
          echo "üìã Syncing latest EC2 setup scripts from Git to S3..."
          echo "Source: ./{{id}}/ec2-setup/"
          echo "Target: s3://${OPS_BUCKET}/ec2-setup/"
          
          # Verify source directory exists
          if [ ! -d "./{{id}}/ec2-setup" ]; then
            echo "‚ùå Source directory ./{{id}}/ec2-setup not found"
            exit 1
          fi
          
          # Show what we're about to sync
          echo "üìÅ Files to sync:"
          ls -la ./{{id}}/ec2-setup/
          
          # Sync EC2 setup scripts to S3 with delete flag to remove old files
          if aws s3 sync ./{{id}}/ec2-setup/ "s3://${OPS_BUCKET}/ec2-setup/" --delete --region {{{githubVarsOpen}}} env.AWS_REGION  {{{githubVarsClose}}}; then
            echo "‚úÖ Successfully synced EC2 setup scripts to S3"
            
            # Verify what was uploaded
            echo "üîç Verifying uploaded files:"
            aws s3 ls "s3://${OPS_BUCKET}/ec2-setup/" --region {{{githubVarsOpen}}} env.AWS_REGION  {{{githubVarsClose}}}
          else
            echo "‚ùå Failed to sync EC2 setup scripts to S3"
            exit 1
          fi

      - name: Deploy - Copy EC2 Setup Scripts and Initialize
        run: |
          echo "üîß Preparing EC2 instances with setup scripts..."
          
          # Convert comma-separated instances to space-separated for AWS CLI
          INSTANCE_LIST=$(echo "${EC2_INSTANCES}" | tr ',' ' ')
          echo "Target instances: ${INSTANCE_LIST}"
          
          # Copy ec2-setup scripts from S3 and run init.sh
          echo "üìã Copying EC2 setup scripts and initializing instances..."
          INIT_COMMAND_ID=$(aws ssm send-command \
            --instance-ids ${INSTANCE_LIST} \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "echo \"=== Syncing EC2 setup scripts from S3 ===\"",
              "sudo mkdir -p /opt/{{backendModule.name}}/ec2-setup",
              "aws s3 sync s3://'${OPS_BUCKET}'/ec2-setup/ /opt/{{backendModule.name}}/ec2-setup/ --region '${AWS_REGION}'",
              "sudo chmod +x /opt/{{backendModule.name}}/ec2-setup/*.sh",
              "echo \"=== Running initialization script ===\"",
              "sudo /opt/{{backendModule.name}}/ec2-setup/init.sh '${JAR_NAME}' '${SPRING_PROFILE}'"
            ]' \
            --timeout-seconds 1800 \
            --query 'Command.CommandId' \
            --output text)
          
          echo "EC2 Setup Command ID: ${INIT_COMMAND_ID}"
          
          echo "‚è≥ Waiting for EC2 setup and initialization to complete..."
          
          # Convert instances to array for status checking
          IFS=' ' read -ra INSTANCE_ARRAY <<< "${INSTANCE_LIST}"
          
          # Wait for command completion on all instances
          for i in {1..120}; do
            ALL_COMPLETE=true
            ALL_SUCCESS=true
            
            echo "=== Checking initialization status (attempt ${i}/120) ==="
            
            for INSTANCE in "${INSTANCE_ARRAY[@]}"; do
              # Trim whitespace
              INSTANCE=$(echo "${INSTANCE}" | xargs)
              
              STATUS=$(aws ssm get-command-invocation \
                --command-id "${INIT_COMMAND_ID}" \
                --instance-id "${INSTANCE}" \
                --query 'Status' \
                --output text 2>/dev/null || echo "InProgress")
              
              echo "üìä Instance ${INSTANCE}: ${STATUS}"
              
              if [ "${STATUS}" = "Failed" ]; then
                echo "‚ùå Initialization failed on instance ${INSTANCE}"
                echo "=== Error Output for ${INSTANCE} ==="
                aws ssm get-command-invocation \
                  --command-id "${INIT_COMMAND_ID}" \
                  --instance-id "${INSTANCE}" \
                  --query 'StandardErrorContent' \
                  --output text
                echo "=== Standard Output for ${INSTANCE} ==="
                aws ssm get-command-invocation \
                  --command-id "${INIT_COMMAND_ID}" \
                  --instance-id "${INSTANCE}" \
                  --query 'StandardOutputContent' \
                  --output text
                exit 1
              elif [ "${STATUS}" != "Success" ]; then
                ALL_SUCCESS=false
                if [ "${STATUS}" = "InProgress" ]; then
                  ALL_COMPLETE=false
                fi
              fi
            done
            
            if [ "${ALL_SUCCESS}" = "true" ]; then
              echo "‚úÖ Initialization completed successfully on all instances"
              
              # Show successful output from all instances
              echo "üîç Initialization results:"
              for INSTANCE in "${INSTANCE_ARRAY[@]}"; do
                INSTANCE=$(echo "${INSTANCE}" | xargs)
                echo "üìã Instance ${INSTANCE} initialization output (last 20 lines):"
                aws ssm get-command-invocation \
                  --command-id "${INIT_COMMAND_ID}" \
                  --instance-id "${INSTANCE}" \
                  --query 'StandardOutputContent' \
                  --output text | tail -n 20
                echo
              done
              break
            fi
            
            if [ "${ALL_COMPLETE}" = "true" ]; then
              echo "‚ùå Some instances completed but not all succeeded"
              exit 1
            fi
            
            sleep 15
          done
          
          # If we reach here without success, it timed out
          if [ "${ALL_SUCCESS}" != "true" ]; then
            echo "‚ùå Initialization timed out after 30 minutes"
            # Show any available output even on timeout
            for INSTANCE in "${INSTANCE_ARRAY[@]}"; do
              INSTANCE=$(echo "${INSTANCE}" | xargs)
              echo "--- Instance ${INSTANCE} Output ---"
              aws ssm get-command-invocation \
                --command-id "${INIT_COMMAND_ID}" \
                --instance-id "${INSTANCE}" \
                --query 'StandardOutputContent' \
                --output text || true
              echo "--- Instance ${INSTANCE} Errors ---"
              aws ssm get-command-invocation \
                --command-id "${INIT_COMMAND_ID}" \
                --instance-id "${INSTANCE}" \
                --query 'StandardErrorContent' \
                --output text || true
              echo
            done
            exit 1
          fi
          echo "‚úÖ EC2 setup and initialization completed"
          echo "üéâ Deployment to {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}} environment completed successfully!"
          echo "üìã Summary:"
          echo "  - JAR: ${JAR_NAME}"
          echo "  - Environment: {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}"
          echo "  - Spring Profile: ${SPRING_PROFILE}"
          echo "  - Instances: ${EC2_INSTANCES}"
          echo "  - Service: {{backendModule.name}}-api.service"

      - name: Enable ALB Health Checks
        run: |
          echo "üîç Checking if ALB health checks are already enabled..."
          
          # Check current health check type
          CURRENT_HEALTH_CHECK=$(aws autoscaling describe-auto-scaling-groups \
            --auto-scaling-group-names "{{projectName}}-{{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}-asg" \
            --query 'AutoScalingGroups[0].HealthCheckType' \
            --output text 2>/dev/null || echo "NONE")
          
          echo "Current health check type: ${CURRENT_HEALTH_CHECK}"
          
          if [ "${CURRENT_HEALTH_CHECK}" = "ELB" ]; then
            echo "‚úÖ ALB health checks are already enabled"
            echo "üîç Current ASG health check configuration:"
            aws autoscaling describe-auto-scaling-groups \
              --auto-scaling-group-names "{{projectName}}-{{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}-asg" \
              --query 'AutoScalingGroups[0].{HealthCheckType:HealthCheckType,HealthCheckGracePeriod:HealthCheckGracePeriod}' \
              --output table
          else
            echo "üîÑ Enabling ALB health checks for Auto Scaling Group..."
            
            # Run the enable health checks script
            cd {{id}}/helper
            chmod +x enable-health-checks.sh
            ./enable-health-checks.sh {{{githubVarsOpen}}} env.ENVIRONMENT  {{{githubVarsClose}}}
            
            echo "‚úÖ ALB health checks enabled successfully!"
          fi